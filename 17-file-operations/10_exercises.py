#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Pythonæ–‡ä»¶æ“ä½œ - ç»¼åˆç»ƒä¹ 

æœ¬æ¨¡å—åŒ…å«æ–‡ä»¶æ“ä½œçš„ç»¼åˆç»ƒä¹ é¢˜ï¼Œæ¶µç›–ï¼š
1. æ–‡æœ¬æ–‡ä»¶å¤„ç†ç»ƒä¹ 
2. äºŒè¿›åˆ¶æ–‡ä»¶æ“ä½œç»ƒä¹ 
3. æ–‡ä»¶ç³»ç»Ÿæ“ä½œç»ƒä¹ 
4. å¼‚å¸¸å¤„ç†ç»ƒä¹ 
5. å®é™…åº”ç”¨åœºæ™¯ç»ƒä¹ 
6. æ€§èƒ½ä¼˜åŒ–ç»ƒä¹ 
7. é«˜çº§æ–‡ä»¶æ“ä½œç»ƒä¹ 

ä½œè€…ï¼šPythonå­¦ä¹ åŠ©æ‰‹
æ—¥æœŸï¼š2024å¹´
"""

import os
import sys
import json
import csv
import shutil
import hashlib
import logging
import tempfile
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from collections import defaultdict, Counter
import time
import random


# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class FileExercises:
    """æ–‡ä»¶æ“ä½œç»ƒä¹ ç±»"""
    
    def __init__(self):
        self.exercise_dir = Path('exercises_temp')
        self.exercise_dir.mkdir(exist_ok=True)
        self.results = {}
    
    def cleanup(self):
        """æ¸…ç†ç»ƒä¹ æ–‡ä»¶"""
        if self.exercise_dir.exists():
            shutil.rmtree(self.exercise_dir)
    
    def exercise_1_text_processing(self):
        """
        ç»ƒä¹ 1ï¼šæ–‡æœ¬æ–‡ä»¶å¤„ç†
        ä»»åŠ¡ï¼šå¤„ç†ä¸€ä¸ªåŒ…å«å­¦ç”Ÿæˆç»©çš„æ–‡æœ¬æ–‡ä»¶
        """
        print("\n=== ç»ƒä¹ 1ï¼šæ–‡æœ¬æ–‡ä»¶å¤„ç† ===")
        print("ä»»åŠ¡ï¼šå¤„ç†å­¦ç”Ÿæˆç»©æ–‡ä»¶ï¼Œè®¡ç®—ç»Ÿè®¡ä¿¡æ¯")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        grades_data = """
å¼ ä¸‰,æ•°å­¦,85
å¼ ä¸‰,è¯­æ–‡,92
å¼ ä¸‰,è‹±è¯­,78
æå››,æ•°å­¦,90
æå››,è¯­æ–‡,88
æå››,è‹±è¯­,95
ç‹äº”,æ•°å­¦,76
ç‹äº”,è¯­æ–‡,82
ç‹äº”,è‹±è¯­,89
èµµå…­,æ•°å­¦,94
èµµå…­,è¯­æ–‡,87
èµµå…­,è‹±è¯­,91
"""
        
        grades_file = self.exercise_dir / 'grades.txt'
        grades_file.write_text(grades_data.strip(), encoding='utf-8')
        
        try:
            # è§£å†³æ–¹æ¡ˆ
            student_grades = defaultdict(dict)
            subject_scores = defaultdict(list)
            
            # è¯»å–å¹¶è§£ææ•°æ®
            with open(grades_file, 'r', encoding='utf-8') as f:
                for line in f:
                    name, subject, score = line.strip().split(',')
                    score = int(score)
                    student_grades[name][subject] = score
                    subject_scores[subject].append(score)
            
            # è®¡ç®—æ¯ä¸ªå­¦ç”Ÿçš„å¹³å‡åˆ†
            print("\nå­¦ç”Ÿå¹³å‡åˆ†ï¼š")
            for name, grades in student_grades.items():
                avg_score = sum(grades.values()) / len(grades)
                print(f"{name}: {avg_score:.2f}")
            
            # è®¡ç®—æ¯ç§‘çš„å¹³å‡åˆ†
            print("\nç§‘ç›®å¹³å‡åˆ†ï¼š")
            for subject, scores in subject_scores.items():
                avg_score = sum(scores) / len(scores)
                print(f"{subject}: {avg_score:.2f}")
            
            # æ‰¾å‡ºæœ€é«˜åˆ†å’Œæœ€ä½åˆ†
            all_scores = []
            for grades in student_grades.values():
                all_scores.extend(grades.values())
            
            print(f"\næœ€é«˜åˆ†: {max(all_scores)}")
            print(f"æœ€ä½åˆ†: {min(all_scores)}")
            
            # ç”Ÿæˆæˆç»©æŠ¥å‘Š
            report_file = self.exercise_dir / 'grade_report.txt'
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("å­¦ç”Ÿæˆç»©æŠ¥å‘Š\n")
                f.write("=" * 30 + "\n\n")
                
                for name, grades in student_grades.items():
                    f.write(f"å­¦ç”Ÿï¼š{name}\n")
                    for subject, score in grades.items():
                        f.write(f"  {subject}: {score}\n")
                    avg = sum(grades.values()) / len(grades)
                    f.write(f"  å¹³å‡åˆ†: {avg:.2f}\n\n")
            
            print(f"æˆç»©æŠ¥å‘Šå·²ç”Ÿæˆï¼š{report_file}")
            self.results['exercise_1'] = 'å®Œæˆ'
            
        except Exception as e:
            print(f"ç»ƒä¹ 1å¤±è´¥ï¼š{e}")
            self.results['exercise_1'] = f'å¤±è´¥: {e}'
    
    def exercise_2_csv_processing(self):
        """
        ç»ƒä¹ 2ï¼šCSVæ–‡ä»¶å¤„ç†
        ä»»åŠ¡ï¼šå¤„ç†é”€å”®æ•°æ®CSVæ–‡ä»¶
        """
        print("\n=== ç»ƒä¹ 2ï¼šCSVæ–‡ä»¶å¤„ç† ===")
        print("ä»»åŠ¡ï¼šåˆ†æé”€å”®æ•°æ®ï¼Œç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š")
        
        # åˆ›å»ºæµ‹è¯•CSVæ•°æ®
        sales_data = [
            ['æ—¥æœŸ', 'äº§å“', 'é”€å”®å‘˜', 'æ•°é‡', 'å•ä»·'],
            ['2024-01-01', 'ç¬”è®°æœ¬ç”µè„‘', 'å¼ ä¸‰', '2', '5000'],
            ['2024-01-01', 'é¼ æ ‡', 'å¼ ä¸‰', '5', '50'],
            ['2024-01-02', 'é”®ç›˜', 'æå››', '3', '200'],
            ['2024-01-02', 'ç¬”è®°æœ¬ç”µè„‘', 'æå››', '1', '5000'],
            ['2024-01-03', 'æ˜¾ç¤ºå™¨', 'ç‹äº”', '2', '1500'],
            ['2024-01-03', 'é¼ æ ‡', 'ç‹äº”', '10', '50'],
            ['2024-01-04', 'ç¬”è®°æœ¬ç”µè„‘', 'å¼ ä¸‰', '3', '5000'],
            ['2024-01-04', 'é”®ç›˜', 'èµµå…­', '5', '200'],
        ]
        
        sales_file = self.exercise_dir / 'sales.csv'
        
        try:
            # å†™å…¥CSVæ–‡ä»¶
            with open(sales_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerows(sales_data)
            
            # è¯»å–å¹¶åˆ†æCSVæ•°æ®
            sales_records = []
            with open(sales_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    row['æ•°é‡'] = int(row['æ•°é‡'])
                    row['å•ä»·'] = float(row['å•ä»·'])
                    row['æ€»é¢'] = row['æ•°é‡'] * row['å•ä»·']
                    sales_records.append(row)
            
            # ç»Ÿè®¡åˆ†æ
            total_sales = sum(record['æ€»é¢'] for record in sales_records)
            print(f"æ€»é”€å”®é¢ï¼š{total_sales:,.2f}å…ƒ")
            
            # æŒ‰äº§å“ç»Ÿè®¡
            product_sales = defaultdict(float)
            for record in sales_records:
                product_sales[record['äº§å“']] += record['æ€»é¢']
            
            print("\näº§å“é”€å”®é¢æ’è¡Œï¼š")
            for product, amount in sorted(product_sales.items(), key=lambda x: x[1], reverse=True):
                print(f"{product}: {amount:,.2f}å…ƒ")
            
            # æŒ‰é”€å”®å‘˜ç»Ÿè®¡
            salesperson_sales = defaultdict(float)
            for record in sales_records:
                salesperson_sales[record['é”€å”®å‘˜']] += record['æ€»é¢']
            
            print("\né”€å”®å‘˜ä¸šç»©æ’è¡Œï¼š")
            for person, amount in sorted(salesperson_sales.items(), key=lambda x: x[1], reverse=True):
                print(f"{person}: {amount:,.2f}å…ƒ")
            
            # ç”Ÿæˆè¯¦ç»†æŠ¥å‘ŠCSV
            report_file = self.exercise_dir / 'sales_report.csv'
            with open(report_file, 'w', newline='', encoding='utf-8') as f:
                fieldnames = ['æ—¥æœŸ', 'äº§å“', 'é”€å”®å‘˜', 'æ•°é‡', 'å•ä»·', 'æ€»é¢']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(sales_records)
            
            print(f"è¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆï¼š{report_file}")
            self.results['exercise_2'] = 'å®Œæˆ'
            
        except Exception as e:
            print(f"ç»ƒä¹ 2å¤±è´¥ï¼š{e}")
            self.results['exercise_2'] = f'å¤±è´¥: {e}'
    
    def exercise_3_json_config(self):
        """
        ç»ƒä¹ 3ï¼šJSONé…ç½®æ–‡ä»¶å¤„ç†
        ä»»åŠ¡ï¼šåˆ›å»ºå’Œç®¡ç†åº”ç”¨ç¨‹åºé…ç½®
        """
        print("\n=== ç»ƒä¹ 3ï¼šJSONé…ç½®æ–‡ä»¶å¤„ç† ===")
        print("ä»»åŠ¡ï¼šç®¡ç†åº”ç”¨ç¨‹åºé…ç½®æ–‡ä»¶")
        
        try:
            # é»˜è®¤é…ç½®
            default_config = {
                'app': {
                    'name': 'MyApp',
                    'version': '1.0.0',
                    'debug': False
                },
                'database': {
                    'host': 'localhost',
                    'port': 5432,
                    'name': 'myapp_db',
                    'user': 'admin'
                },
                'logging': {
                    'level': 'INFO',
                    'file': 'app.log',
                    'max_size': '10MB'
                },
                'features': {
                    'email_notifications': True,
                    'auto_backup': True,
                    'analytics': False
                }
            }
            
            config_file = self.exercise_dir / 'config.json'
            
            # ä¿å­˜é»˜è®¤é…ç½®
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(default_config, f, indent=2, ensure_ascii=False)
            
            print(f"é»˜è®¤é…ç½®å·²åˆ›å»ºï¼š{config_file}")
            
            # è¯»å–é…ç½®
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            print("\nå½“å‰é…ç½®ï¼š")
            print(json.dumps(config, indent=2, ensure_ascii=False))
            
            # ä¿®æ”¹é…ç½®
            config['app']['debug'] = True
            config['database']['port'] = 3306
            config['features']['analytics'] = True
            
            # æ·»åŠ æ–°çš„é…ç½®é¡¹
            config['cache'] = {
                'type': 'redis',
                'host': 'localhost',
                'port': 6379,
                'ttl': 3600
            }
            
            # ä¿å­˜ä¿®æ”¹åçš„é…ç½®
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            print("\né…ç½®å·²æ›´æ–°")
            
            # åˆ›å»ºé…ç½®å¤‡ä»½
            backup_file = self.exercise_dir / f'config_backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
            shutil.copy2(config_file, backup_file)
            print(f"é…ç½®å¤‡ä»½å·²åˆ›å»ºï¼š{backup_file}")
            
            # éªŒè¯é…ç½®
            def validate_config(cfg):
                """éªŒè¯é…ç½®æ–‡ä»¶"""
                required_keys = ['app', 'database', 'logging']
                for key in required_keys:
                    if key not in cfg:
                        raise ValueError(f"ç¼ºå°‘å¿…éœ€çš„é…ç½®é¡¹ï¼š{key}")
                
                if not isinstance(cfg['database']['port'], int):
                    raise ValueError("æ•°æ®åº“ç«¯å£å¿…é¡»æ˜¯æ•´æ•°")
                
                if cfg['database']['port'] < 1 or cfg['database']['port'] > 65535:
                    raise ValueError("æ•°æ®åº“ç«¯å£å¿…é¡»åœ¨1-65535èŒƒå›´å†…")
                
                return True
            
            validate_config(config)
            print("é…ç½®éªŒè¯é€šè¿‡")
            
            self.results['exercise_3'] = 'å®Œæˆ'
            
        except Exception as e:
            print(f"ç»ƒä¹ 3å¤±è´¥ï¼š{e}")
            self.results['exercise_3'] = f'å¤±è´¥: {e}'
    
    def exercise_4_binary_file_analysis(self):
        """
        ç»ƒä¹ 4ï¼šäºŒè¿›åˆ¶æ–‡ä»¶åˆ†æ
        ä»»åŠ¡ï¼šåˆ†ææ–‡ä»¶ç±»å‹å’Œè®¡ç®—æ–‡ä»¶å“ˆå¸Œ
        """
        print("\n=== ç»ƒä¹ 4ï¼šäºŒè¿›åˆ¶æ–‡ä»¶åˆ†æ ===")
        print("ä»»åŠ¡ï¼šåˆ†ææ–‡ä»¶ç±»å‹ï¼Œè®¡ç®—å“ˆå¸Œå€¼")
        
        try:
            # åˆ›å»ºä¸åŒç±»å‹çš„æµ‹è¯•æ–‡ä»¶
            test_files = {
                'text.txt': b'Hello, World! This is a text file.',
                'image.png': b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01\x08\x02\x00\x00\x00\x90wS\xde',
                'pdf.pdf': b'%PDF-1.4\n1 0 obj\n<<\n/Type /Catalog\n/Pages 2 0 R\n>>\nendobj',
                'zip.zip': b'PK\x03\x04\x14\x00\x00\x00\x08\x00',
                'exe.exe': b'MZ\x90\x00\x03\x00\x00\x00\x04\x00\x00\x00\xff\xff\x00\x00'
            }
            
            # æ–‡ä»¶ç±»å‹ç­¾å
            file_signatures = {
                b'\x89PNG': 'PNGå›¾åƒ',
                b'%PDF': 'PDFæ–‡æ¡£',
                b'PK\x03\x04': 'ZIPå‹ç¼©æ–‡ä»¶',
                b'MZ': 'Windowså¯æ‰§è¡Œæ–‡ä»¶',
                b'\xff\xd8\xff': 'JPEGå›¾åƒ',
                b'GIF8': 'GIFå›¾åƒ'
            }
            
            # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
            for filename, content in test_files.items():
                file_path = self.exercise_dir / filename
                file_path.write_bytes(content)
            
            print("\næ–‡ä»¶åˆ†æç»“æœï¼š")
            print("-" * 60)
            
            for filename in test_files.keys():
                file_path = self.exercise_dir / filename
                
                # è¯»å–æ–‡ä»¶å¤´
                with open(file_path, 'rb') as f:
                    header = f.read(16)
                
                # è¯†åˆ«æ–‡ä»¶ç±»å‹
                file_type = 'æœªçŸ¥ç±»å‹'
                for signature, type_name in file_signatures.items():
                    if header.startswith(signature):
                        file_type = type_name
                        break
                
                # è®¡ç®—æ–‡ä»¶å¤§å°
                file_size = file_path.stat().st_size
                
                # è®¡ç®—MD5å“ˆå¸Œ
                md5_hash = hashlib.md5()
                with open(file_path, 'rb') as f:
                    for chunk in iter(lambda: f.read(4096), b''):
                        md5_hash.update(chunk)
                
                # è®¡ç®—SHA256å“ˆå¸Œ
                sha256_hash = hashlib.sha256()
                with open(file_path, 'rb') as f:
                    for chunk in iter(lambda: f.read(4096), b''):
                        sha256_hash.update(chunk)
                
                print(f"æ–‡ä»¶å: {filename}")
                print(f"ç±»å‹: {file_type}")
                print(f"å¤§å°: {file_size} å­—èŠ‚")
                print(f"MD5: {md5_hash.hexdigest()}")
                print(f"SHA256: {sha256_hash.hexdigest()}")
                print(f"æ–‡ä»¶å¤´: {header.hex()[:32]}...")
                print("-" * 60)
            
            # ç”Ÿæˆåˆ†ææŠ¥å‘Š
            report_file = self.exercise_dir / 'file_analysis_report.txt'
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("æ–‡ä»¶åˆ†ææŠ¥å‘Š\n")
                f.write("=" * 50 + "\n\n")
                f.write(f"åˆ†ææ—¶é—´: {datetime.now()}\n")
                f.write(f"åˆ†ææ–‡ä»¶æ•°é‡: {len(test_files)}\n\n")
                
                for filename in test_files.keys():
                    file_path = self.exercise_dir / filename
                    file_size = file_path.stat().st_size
                    
                    with open(file_path, 'rb') as file:
                        header = file.read(16)
                    
                    file_type = 'æœªçŸ¥ç±»å‹'
                    for signature, type_name in file_signatures.items():
                        if header.startswith(signature):
                            file_type = type_name
                            break
                    
                    f.write(f"æ–‡ä»¶: {filename}\n")
                    f.write(f"ç±»å‹: {file_type}\n")
                    f.write(f"å¤§å°: {file_size} å­—èŠ‚\n")
                    f.write(f"ä¿®æ”¹æ—¶é—´: {datetime.fromtimestamp(file_path.stat().st_mtime)}\n\n")
            
            print(f"åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆï¼š{report_file}")
            self.results['exercise_4'] = 'å®Œæˆ'
            
        except Exception as e:
            print(f"ç»ƒä¹ 4å¤±è´¥ï¼š{e}")
            self.results['exercise_4'] = f'å¤±è´¥: {e}'
    
    def exercise_5_log_analysis(self):
        """
        ç»ƒä¹ 5ï¼šæ—¥å¿—æ–‡ä»¶åˆ†æ
        ä»»åŠ¡ï¼šåˆ†æWebæœåŠ¡å™¨æ—¥å¿—
        """
        print("\n=== ç»ƒä¹ 5ï¼šæ—¥å¿—æ–‡ä»¶åˆ†æ ===")
        print("ä»»åŠ¡ï¼šåˆ†æWebæœåŠ¡å™¨è®¿é—®æ—¥å¿—")
        
        try:
            # ç”Ÿæˆæ¨¡æ‹Ÿæ—¥å¿—æ•°æ®
            log_entries = []
            ips = ['192.168.1.100', '10.0.0.50', '172.16.0.25', '203.0.113.10', '198.51.100.5']
            paths = ['/', '/index.html', '/about.html', '/contact.html', '/api/users', '/api/products', '/login', '/admin']
            status_codes = [200, 200, 200, 200, 404, 500, 301, 403]
            user_agents = [
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
                'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36'
            ]
            
            # ç”Ÿæˆ100æ¡æ—¥å¿—è®°å½•
            for i in range(100):
                timestamp = datetime.now().strftime('%d/%b/%Y:%H:%M:%S +0000')
                ip = random.choice(ips)
                path = random.choice(paths)
                status = random.choice(status_codes)
                size = random.randint(100, 10000)
                user_agent = random.choice(user_agents)
                
                log_entry = f'{ip} - - [{timestamp}] "GET {path} HTTP/1.1" {status} {size} "-" "{user_agent}"'
                log_entries.append(log_entry)
            
            # å†™å…¥æ—¥å¿—æ–‡ä»¶
            log_file = self.exercise_dir / 'access.log'
            with open(log_file, 'w', encoding='utf-8') as f:
                f.write('\n'.join(log_entries))
            
            print(f"æ¨¡æ‹Ÿæ—¥å¿—æ–‡ä»¶å·²åˆ›å»ºï¼š{log_file}")
            
            # åˆ†ææ—¥å¿—
            ip_counter = Counter()
            path_counter = Counter()
            status_counter = Counter()
            total_bytes = 0
            error_logs = []
            
            with open(log_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    try:
                        # ç®€å•çš„æ—¥å¿—è§£æï¼ˆå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„æ­£åˆ™è¡¨è¾¾å¼ï¼‰
                        parts = line.strip().split()
                        if len(parts) >= 10:
                            ip = parts[0]
                            path = parts[6]
                            status = parts[8]
                            size = int(parts[9]) if parts[9].isdigit() else 0
                            
                            ip_counter[ip] += 1
                            path_counter[path] += 1
                            status_counter[status] += 1
                            total_bytes += size
                            
                            # è®°å½•é”™è¯¯æ—¥å¿—
                            if status.startswith('4') or status.startswith('5'):
                                error_logs.append((line_num, line.strip()))
                    
                    except (ValueError, IndexError) as e:
                        print(f"è§£æç¬¬{line_num}è¡Œæ—¶å‡ºé”™ï¼š{e}")
            
            # ç”Ÿæˆåˆ†ææŠ¥å‘Š
            print("\n=== æ—¥å¿—åˆ†æç»“æœ ===")
            
            print(f"\næ€»è¯·æ±‚æ•°ï¼š{sum(ip_counter.values())}")
            print(f"æ€»æµé‡ï¼š{total_bytes:,} å­—èŠ‚ ({total_bytes/1024/1024:.2f} MB)")
            print(f"é”™è¯¯è¯·æ±‚æ•°ï¼š{len(error_logs)}")
            
            print("\nè®¿é—®æœ€å¤šçš„IPåœ°å€ï¼š")
            for ip, count in ip_counter.most_common(5):
                print(f"{ip}: {count} æ¬¡")
            
            print("\nè®¿é—®æœ€å¤šçš„é¡µé¢ï¼š")
            for path, count in path_counter.most_common(5):
                print(f"{path}: {count} æ¬¡")
            
            print("\nçŠ¶æ€ç åˆ†å¸ƒï¼š")
            for status, count in status_counter.most_common():
                print(f"{status}: {count} æ¬¡")
            
            # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šæ–‡ä»¶
            report_file = self.exercise_dir / 'log_analysis_report.txt'
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("WebæœåŠ¡å™¨æ—¥å¿—åˆ†ææŠ¥å‘Š\n")
                f.write("=" * 50 + "\n\n")
                f.write(f"åˆ†ææ—¶é—´: {datetime.now()}\n")
                f.write(f"æ—¥å¿—æ–‡ä»¶: {log_file}\n")
                f.write(f"æ€»è¯·æ±‚æ•°: {sum(ip_counter.values())}\n")
                f.write(f"æ€»æµé‡: {total_bytes:,} å­—èŠ‚\n")
                f.write(f"é”™è¯¯è¯·æ±‚æ•°: {len(error_logs)}\n\n")
                
                f.write("è®¿é—®æœ€å¤šçš„IPåœ°å€:\n")
                for ip, count in ip_counter.most_common(10):
                    f.write(f"{ip}: {count} æ¬¡\n")
                
                f.write("\nè®¿é—®æœ€å¤šçš„é¡µé¢:\n")
                for path, count in path_counter.most_common(10):
                    f.write(f"{path}: {count} æ¬¡\n")
                
                f.write("\nçŠ¶æ€ç åˆ†å¸ƒ:\n")
                for status, count in status_counter.most_common():
                    f.write(f"{status}: {count} æ¬¡\n")
                
                if error_logs:
                    f.write("\né”™è¯¯æ—¥å¿—è®°å½•:\n")
                    for line_num, log_line in error_logs[:20]:  # åªæ˜¾ç¤ºå‰20æ¡é”™è¯¯
                        f.write(f"ç¬¬{line_num}è¡Œ: {log_line}\n")
            
            print(f"è¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆï¼š{report_file}")
            self.results['exercise_5'] = 'å®Œæˆ'
            
        except Exception as e:
            print(f"ç»ƒä¹ 5å¤±è´¥ï¼š{e}")
            self.results['exercise_5'] = f'å¤±è´¥: {e}'
    
    def exercise_6_file_backup_system(self):
        """
        ç»ƒä¹ 6ï¼šæ–‡ä»¶å¤‡ä»½ç³»ç»Ÿ
        ä»»åŠ¡ï¼šå®ç°ä¸€ä¸ªç®€å•çš„æ–‡ä»¶å¤‡ä»½ç³»ç»Ÿ
        """
        print("\n=== ç»ƒä¹ 6ï¼šæ–‡ä»¶å¤‡ä»½ç³»ç»Ÿ ===")
        print("ä»»åŠ¡ï¼šå®ç°æ–‡ä»¶å¤‡ä»½å’Œæ¢å¤åŠŸèƒ½")
        
        try:
            # åˆ›å»ºæºæ–‡ä»¶ç›®å½•å’Œæ–‡ä»¶
            source_dir = self.exercise_dir / 'source'
            backup_dir = self.exercise_dir / 'backup'
            source_dir.mkdir(exist_ok=True)
            backup_dir.mkdir(exist_ok=True)
            
            # åˆ›å»ºä¸€äº›æµ‹è¯•æ–‡ä»¶
            test_files = {
                'document1.txt': 'è¿™æ˜¯ç¬¬ä¸€ä¸ªæ–‡æ¡£çš„å†…å®¹',
                'document2.txt': 'è¿™æ˜¯ç¬¬äºŒä¸ªæ–‡æ¡£çš„å†…å®¹',
                'config.json': json.dumps({'setting1': 'value1', 'setting2': 'value2'}, indent=2),
                'data.csv': 'name,age,city\nAlice,25,New York\nBob,30,London'
            }
            
            for filename, content in test_files.items():
                (source_dir / filename).write_text(content, encoding='utf-8')
            
            print(f"æºæ–‡ä»¶å·²åˆ›å»ºåœ¨ï¼š{source_dir}")
            
            def create_backup(src_dir: Path, backup_dir: Path, backup_name: str = None):
                """åˆ›å»ºå¤‡ä»½"""
                if not backup_name:
                    backup_name = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                
                backup_path = backup_dir / backup_name
                backup_path.mkdir(exist_ok=True)
                
                backup_info = {
                    'timestamp': datetime.now().isoformat(),
                    'source_dir': str(src_dir),
                    'files': []
                }
                
                # å¤åˆ¶æ–‡ä»¶å¹¶è®°å½•ä¿¡æ¯
                for file_path in src_dir.rglob('*'):
                    if file_path.is_file():
                        relative_path = file_path.relative_to(src_dir)
                        dest_path = backup_path / relative_path
                        dest_path.parent.mkdir(parents=True, exist_ok=True)
                        
                        shutil.copy2(file_path, dest_path)
                        
                        # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
                        with open(file_path, 'rb') as f:
                            file_hash = hashlib.md5(f.read()).hexdigest()
                        
                        backup_info['files'].append({
                            'path': str(relative_path),
                            'size': file_path.stat().st_size,
                            'modified': datetime.fromtimestamp(file_path.stat().st_mtime).isoformat(),
                            'hash': file_hash
                        })
                
                # ä¿å­˜å¤‡ä»½ä¿¡æ¯
                info_file = backup_path / 'backup_info.json'
                with open(info_file, 'w', encoding='utf-8') as f:
                    json.dump(backup_info, f, indent=2, ensure_ascii=False)
                
                return backup_path, backup_info
            
            def list_backups(backup_dir: Path):
                """åˆ—å‡ºæ‰€æœ‰å¤‡ä»½"""
                backups = []
                for backup_path in backup_dir.iterdir():
                    if backup_path.is_dir():
                        info_file = backup_path / 'backup_info.json'
                        if info_file.exists():
                            with open(info_file, 'r', encoding='utf-8') as f:
                                backup_info = json.load(f)
                            backups.append((backup_path.name, backup_info))
                return sorted(backups, key=lambda x: x[1]['timestamp'], reverse=True)
            
            def restore_backup(backup_dir: Path, backup_name: str, restore_dir: Path):
                """æ¢å¤å¤‡ä»½"""
                backup_path = backup_dir / backup_name
                info_file = backup_path / 'backup_info.json'
                
                if not info_file.exists():
                    raise FileNotFoundError(f"å¤‡ä»½ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨ï¼š{info_file}")
                
                with open(info_file, 'r', encoding='utf-8') as f:
                    backup_info = json.load(f)
                
                restore_dir.mkdir(parents=True, exist_ok=True)
                
                restored_files = []
                for file_info in backup_info['files']:
                    src_file = backup_path / file_info['path']
                    dest_file = restore_dir / file_info['path']
                    dest_file.parent.mkdir(parents=True, exist_ok=True)
                    
                    shutil.copy2(src_file, dest_file)
                    restored_files.append(file_info['path'])
                
                return restored_files
            
            # æ‰§è¡Œå¤‡ä»½æ“ä½œ
            print("\nåˆ›å»ºå¤‡ä»½...")
            backup_path, backup_info = create_backup(source_dir, backup_dir)
            print(f"å¤‡ä»½å·²åˆ›å»ºï¼š{backup_path}")
            print(f"å¤‡ä»½äº† {len(backup_info['files'])} ä¸ªæ–‡ä»¶")
            
            # ä¿®æ”¹æºæ–‡ä»¶
            print("\nä¿®æ”¹æºæ–‡ä»¶...")
            (source_dir / 'document1.txt').write_text('ä¿®æ”¹åçš„æ–‡æ¡£å†…å®¹', encoding='utf-8')
            (source_dir / 'new_file.txt').write_text('è¿™æ˜¯æ–°æ·»åŠ çš„æ–‡ä»¶', encoding='utf-8')
            
            # åˆ›å»ºç¬¬äºŒä¸ªå¤‡ä»½
            time.sleep(1)  # ç¡®ä¿æ—¶é—´æˆ³ä¸åŒ
            backup_path2, backup_info2 = create_backup(source_dir, backup_dir)
            print(f"ç¬¬äºŒä¸ªå¤‡ä»½å·²åˆ›å»ºï¼š{backup_path2}")
            
            # åˆ—å‡ºæ‰€æœ‰å¤‡ä»½
            print("\nå¯ç”¨çš„å¤‡ä»½ï¼š")
            backups = list_backups(backup_dir)
            for i, (backup_name, info) in enumerate(backups, 1):
                print(f"{i}. {backup_name} - {info['timestamp']} ({len(info['files'])} ä¸ªæ–‡ä»¶)")
            
            # æ¢å¤ç¬¬ä¸€ä¸ªå¤‡ä»½
            print("\næ¢å¤ç¬¬ä¸€ä¸ªå¤‡ä»½...")
            restore_dir = self.exercise_dir / 'restored'
            if backups:
                first_backup_name = backups[-1][0]  # æœ€æ—©çš„å¤‡ä»½
                restored_files = restore_backup(backup_dir, first_backup_name, restore_dir)
                print(f"å·²æ¢å¤ {len(restored_files)} ä¸ªæ–‡ä»¶åˆ°ï¼š{restore_dir}")
                
                # éªŒè¯æ¢å¤çš„æ–‡ä»¶
                print("\næ¢å¤çš„æ–‡ä»¶å†…å®¹ï¼š")
                for filename in ['document1.txt', 'document2.txt']:
                    restored_file = restore_dir / filename
                    if restored_file.exists():
                        content = restored_file.read_text(encoding='utf-8')
                        print(f"{filename}: {content[:50]}...")
            
            self.results['exercise_6'] = 'å®Œæˆ'
            
        except Exception as e:
            print(f"ç»ƒä¹ 6å¤±è´¥ï¼š{e}")
            self.results['exercise_6'] = f'å¤±è´¥: {e}'
    
    def exercise_7_performance_optimization(self):
        """
        ç»ƒä¹ 7ï¼šæ–‡ä»¶æ“ä½œæ€§èƒ½ä¼˜åŒ–
        ä»»åŠ¡ï¼šæ¯”è¾ƒä¸åŒæ–‡ä»¶æ“ä½œæ–¹æ³•çš„æ€§èƒ½
        """
        print("\n=== ç»ƒä¹ 7ï¼šæ–‡ä»¶æ“ä½œæ€§èƒ½ä¼˜åŒ– ===")
        print("ä»»åŠ¡ï¼šæµ‹è¯•å’Œä¼˜åŒ–æ–‡ä»¶æ“ä½œæ€§èƒ½")
        
        try:
            # åˆ›å»ºå¤§æ–‡ä»¶ç”¨äºæµ‹è¯•
            test_file = self.exercise_dir / 'large_test_file.txt'
            
            print("åˆ›å»ºæµ‹è¯•æ–‡ä»¶...")
            with open(test_file, 'w', encoding='utf-8') as f:
                for i in range(10000):
                    f.write(f"è¿™æ˜¯ç¬¬{i+1}è¡Œçš„æµ‹è¯•æ•°æ®ï¼ŒåŒ…å«ä¸€äº›éšæœºå†…å®¹ç”¨äºæµ‹è¯•æ–‡ä»¶æ“ä½œæ€§èƒ½ã€‚\n")
            
            file_size = test_file.stat().st_size
            print(f"æµ‹è¯•æ–‡ä»¶å¤§å°ï¼š{file_size:,} å­—èŠ‚ ({file_size/1024/1024:.2f} MB)")
            
            def time_operation(operation_name: str, operation_func):
                """æµ‹é‡æ“ä½œæ—¶é—´"""
                start_time = time.time()
                result = operation_func()
                end_time = time.time()
                duration = end_time - start_time
                print(f"{operation_name}: {duration:.4f}ç§’")
                return result, duration
            
            # æµ‹è¯•1ï¼šä¸åŒçš„è¯»å–æ–¹æ³•
            print("\n=== è¯»å–æ€§èƒ½æµ‹è¯• ===")
            
            def read_all_at_once():
                with open(test_file, 'r', encoding='utf-8') as f:
                    return len(f.read())
            
            def read_line_by_line():
                count = 0
                with open(test_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        count += len(line)
                return count
            
            def read_with_buffer():
                count = 0
                with open(test_file, 'r', encoding='utf-8', buffering=8192) as f:
                    while True:
                        chunk = f.read(1024)
                        if not chunk:
                            break
                        count += len(chunk)
                return count
            
            def read_with_readlines():
                with open(test_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                return sum(len(line) for line in lines)
            
            # æ‰§è¡Œè¯»å–æµ‹è¯•
            read_results = {}
            read_results['read_all'], read_results['read_all_time'] = time_operation("ä¸€æ¬¡æ€§è¯»å–å…¨éƒ¨", read_all_at_once)
            read_results['read_lines'], read_results['read_lines_time'] = time_operation("é€è¡Œè¯»å–", read_line_by_line)
            read_results['read_buffer'], read_results['read_buffer_time'] = time_operation("ç¼“å†²è¯»å–", read_with_buffer)
            read_results['read_readlines'], read_results['read_readlines_time'] = time_operation("readlinesè¯»å–", read_with_readlines)
            
            # æµ‹è¯•2ï¼šä¸åŒçš„å†™å…¥æ–¹æ³•
            print("\n=== å†™å…¥æ€§èƒ½æµ‹è¯• ===")
            
            test_data = [f"æµ‹è¯•è¡Œ{i}\n" for i in range(5000)]
            
            def write_all_at_once():
                output_file = self.exercise_dir / 'write_test_1.txt'
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(''.join(test_data))
                return output_file.stat().st_size
            
            def write_line_by_line():
                output_file = self.exercise_dir / 'write_test_2.txt'
                with open(output_file, 'w', encoding='utf-8') as f:
                    for line in test_data:
                        f.write(line)
                return output_file.stat().st_size
            
            def write_with_writelines():
                output_file = self.exercise_dir / 'write_test_3.txt'
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.writelines(test_data)
                return output_file.stat().st_size
            
            def write_with_buffer():
                output_file = self.exercise_dir / 'write_test_4.txt'
                with open(output_file, 'w', encoding='utf-8', buffering=8192) as f:
                    for line in test_data:
                        f.write(line)
                return output_file.stat().st_size
            
            # æ‰§è¡Œå†™å…¥æµ‹è¯•
            write_results = {}
            write_results['write_all'], write_results['write_all_time'] = time_operation("ä¸€æ¬¡æ€§å†™å…¥å…¨éƒ¨", write_all_at_once)
            write_results['write_lines'], write_results['write_lines_time'] = time_operation("é€è¡Œå†™å…¥", write_line_by_line)
            write_results['write_writelines'], write_results['write_writelines_time'] = time_operation("writelineså†™å…¥", write_with_writelines)
            write_results['write_buffer'], write_results['write_buffer_time'] = time_operation("ç¼“å†²å†™å…¥", write_with_buffer)
            
            # æµ‹è¯•3ï¼šæ–‡ä»¶å¤åˆ¶æ€§èƒ½
            print("\n=== æ–‡ä»¶å¤åˆ¶æ€§èƒ½æµ‹è¯• ===")
            
            def copy_with_shutil():
                dest_file = self.exercise_dir / 'copy_shutil.txt'
                shutil.copy2(test_file, dest_file)
                return dest_file.stat().st_size
            
            def copy_with_read_write():
                dest_file = self.exercise_dir / 'copy_manual.txt'
                with open(test_file, 'rb') as src, open(dest_file, 'wb') as dst:
                    dst.write(src.read())
                return dest_file.stat().st_size
            
            def copy_with_chunks():
                dest_file = self.exercise_dir / 'copy_chunks.txt'
                with open(test_file, 'rb') as src, open(dest_file, 'wb') as dst:
                    while True:
                        chunk = src.read(8192)
                        if not chunk:
                            break
                        dst.write(chunk)
                return dest_file.stat().st_size
            
            # æ‰§è¡Œå¤åˆ¶æµ‹è¯•
            copy_results = {}
            copy_results['shutil'], copy_results['shutil_time'] = time_operation("shutil.copy2", copy_with_shutil)
            copy_results['manual'], copy_results['manual_time'] = time_operation("æ‰‹åŠ¨è¯»å†™", copy_with_read_write)
            copy_results['chunks'], copy_results['chunks_time'] = time_operation("åˆ†å—å¤åˆ¶", copy_with_chunks)
            
            # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
            print("\n=== æ€§èƒ½æµ‹è¯•æ€»ç»“ ===")
            print("\nè¯»å–æ€§èƒ½æ’åï¼ˆä»å¿«åˆ°æ…¢ï¼‰ï¼š")
            read_times = [
                ('ä¸€æ¬¡æ€§è¯»å–', read_results['read_all_time']),
                ('ç¼“å†²è¯»å–', read_results['read_buffer_time']),
                ('é€è¡Œè¯»å–', read_results['read_lines_time']),
                ('readlinesè¯»å–', read_results['read_readlines_time'])
            ]
            for i, (method, time_taken) in enumerate(sorted(read_times, key=lambda x: x[1]), 1):
                print(f"{i}. {method}: {time_taken:.4f}ç§’")
            
            print("\nå†™å…¥æ€§èƒ½æ’åï¼ˆä»å¿«åˆ°æ…¢ï¼‰ï¼š")
            write_times = [
                ('ä¸€æ¬¡æ€§å†™å…¥', write_results['write_all_time']),
                ('writelineså†™å…¥', write_results['write_writelines_time']),
                ('ç¼“å†²å†™å…¥', write_results['write_buffer_time']),
                ('é€è¡Œå†™å…¥', write_results['write_lines_time'])
            ]
            for i, (method, time_taken) in enumerate(sorted(write_times, key=lambda x: x[1]), 1):
                print(f"{i}. {method}: {time_taken:.4f}ç§’")
            
            print("\nå¤åˆ¶æ€§èƒ½æ’åï¼ˆä»å¿«åˆ°æ…¢ï¼‰ï¼š")
            copy_times = [
                ('shutil.copy2', copy_results['shutil_time']),
                ('åˆ†å—å¤åˆ¶', copy_results['chunks_time']),
                ('æ‰‹åŠ¨è¯»å†™', copy_results['manual_time'])
            ]
            for i, (method, time_taken) in enumerate(sorted(copy_times, key=lambda x: x[1]), 1):
                print(f"{i}. {method}: {time_taken:.4f}ç§’")
            
            # ä¿å­˜æ€§èƒ½æŠ¥å‘Š
            report_file = self.exercise_dir / 'performance_report.json'
            performance_data = {
                'test_file_size': file_size,
                'test_timestamp': datetime.now().isoformat(),
                'read_performance': {
                    'read_all': read_results['read_all_time'],
                    'read_lines': read_results['read_lines_time'],
                    'read_buffer': read_results['read_buffer_time'],
                    'read_readlines': read_results['read_readlines_time']
                },
                'write_performance': {
                    'write_all': write_results['write_all_time'],
                    'write_lines': write_results['write_lines_time'],
                    'write_writelines': write_results['write_writelines_time'],
                    'write_buffer': write_results['write_buffer_time']
                },
                'copy_performance': {
                    'shutil': copy_results['shutil_time'],
                    'manual': copy_results['manual_time'],
                    'chunks': copy_results['chunks_time']
                }
            }
            
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(performance_data, f, indent=2)
            
            print(f"\næ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜ï¼š{report_file}")
            self.results['exercise_7'] = 'å®Œæˆ'
            
        except Exception as e:
            print(f"ç»ƒä¹ 7å¤±è´¥ï¼š{e}")
            self.results['exercise_7'] = f'å¤±è´¥: {e}'
    
    def run_all_exercises(self):
        """è¿è¡Œæ‰€æœ‰ç»ƒä¹ """
        print("å¼€å§‹æ‰§è¡Œæ–‡ä»¶æ“ä½œç»¼åˆç»ƒä¹ ")
        print("=" * 60)
        
        exercises = [
            self.exercise_1_text_processing,
            self.exercise_2_csv_processing,
            self.exercise_3_json_config,
            self.exercise_4_binary_file_analysis,
            self.exercise_5_log_analysis,
            self.exercise_6_file_backup_system,
            self.exercise_7_performance_optimization
        ]
        
        start_time = time.time()
        
        for i, exercise in enumerate(exercises, 1):
            try:
                print(f"\n{'='*20} ç»ƒä¹  {i} {'='*20}")
                exercise()
            except Exception as e:
                print(f"ç»ƒä¹ {i}æ‰§è¡Œå¤±è´¥ï¼š{e}")
                self.results[f'exercise_{i}'] = f'å¼‚å¸¸: {e}'
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        print("\n" + "=" * 60)
        print("=== ç»ƒä¹ å®Œæˆæ€»ç»“ ===")
        print(f"æ€»æ‰§è¡Œæ—¶é—´ï¼š{total_time:.2f}ç§’")
        print(f"ç»ƒä¹ ç›®å½•ï¼š{self.exercise_dir}")
        
        print("\nå„ç»ƒä¹ å®Œæˆæƒ…å†µï¼š")
        for i in range(1, 8):
            exercise_key = f'exercise_{i}'
            status = self.results.get(exercise_key, 'æœªæ‰§è¡Œ')
            print(f"ç»ƒä¹ {i}ï¼š{status}")
        
        # ä¿å­˜æ€»ç»“æŠ¥å‘Š
        summary_file = self.exercise_dir / 'exercise_summary.json'
        summary_data = {
            'completion_time': datetime.now().isoformat(),
            'total_duration': total_time,
            'exercise_results': self.results,
            'exercise_directory': str(self.exercise_dir)
        }
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary_data, f, indent=2, ensure_ascii=False)
        
        print(f"\næ€»ç»“æŠ¥å‘Šå·²ä¿å­˜ï¼š{summary_file}")
        
        return self.results


def main():
    """ä¸»å‡½æ•°"""
    print("Pythonæ–‡ä»¶æ“ä½œ - ç»¼åˆç»ƒä¹ ")
    print("=" * 50)
    
    # åˆ›å»ºç»ƒä¹ å®ä¾‹
    exercises = FileExercises()
    
    try:
        # è¿è¡Œæ‰€æœ‰ç»ƒä¹ 
        results = exercises.run_all_exercises()
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        print("\n" + "=" * 50)
        print("=== æœ€ç»ˆç»“æœ ===")
        
        completed = sum(1 for status in results.values() if status == 'å®Œæˆ')
        total = len(results)
        
        print(f"å®Œæˆç»ƒä¹ ï¼š{completed}/{total}")
        print(f"æˆåŠŸç‡ï¼š{completed/total*100:.1f}%")
        
        if completed == total:
            print("\nğŸ‰ æ­å–œï¼æ‰€æœ‰ç»ƒä¹ éƒ½å·²å®Œæˆï¼")
        else:
            print("\nğŸ’¡ éƒ¨åˆ†ç»ƒä¹ éœ€è¦é‡æ–°æ£€æŸ¥ï¼Œè¯·æŸ¥çœ‹å…·ä½“é”™è¯¯ä¿¡æ¯ã€‚")
    
    except KeyboardInterrupt:
        print("\nç»ƒä¹ è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nç»ƒä¹ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{e}")
        logger.error(f"ä¸»ç¨‹åºå¼‚å¸¸ï¼š{e}", exc_info=True)
    finally:
        # è¯¢é—®æ˜¯å¦æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            response = input("\næ˜¯å¦åˆ é™¤ç»ƒä¹ ä¸´æ—¶æ–‡ä»¶ï¼Ÿ(y/N): ").strip().lower()
            if response in ['y', 'yes']:
                exercises.cleanup()
                print("ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
            else:
                print(f"ç»ƒä¹ æ–‡ä»¶ä¿ç•™åœ¨ï¼š{exercises.exercise_dir}")
        except (EOFError, KeyboardInterrupt):
            print(f"\nç»ƒä¹ æ–‡ä»¶ä¿ç•™åœ¨ï¼š{exercises.exercise_dir}")
    
    # å­¦ä¹ æ€»ç»“
    print("\n" + "=" * 50)
    print("=== å­¦ä¹ æ€»ç»“ ===")
    print("""
æ–‡ä»¶æ“ä½œç»¼åˆç»ƒä¹ æ¶µç›–çš„çŸ¥è¯†ç‚¹ï¼š

1. æ–‡æœ¬æ–‡ä»¶å¤„ç†ï¼š
   - è¯»å–å’Œè§£æç»“æ„åŒ–æ–‡æœ¬æ•°æ®
   - æ•°æ®ç»Ÿè®¡å’Œåˆ†æ
   - ç”Ÿæˆæ ¼å¼åŒ–æŠ¥å‘Š

2. CSVæ–‡ä»¶æ“ä½œï¼š
   - ä½¿ç”¨csvæ¨¡å—è¯»å†™CSVæ–‡ä»¶
   - æ•°æ®èšåˆå’Œæ’åº
   - å­—å…¸æ ¼å¼çš„æ•°æ®å¤„ç†

3. JSONé…ç½®ç®¡ç†ï¼š
   - JSONæ•°æ®çš„åºåˆ—åŒ–å’Œååºåˆ—åŒ–
   - é…ç½®æ–‡ä»¶çš„è¯»å–ã€ä¿®æ”¹å’ŒéªŒè¯
   - é…ç½®å¤‡ä»½å’Œç‰ˆæœ¬ç®¡ç†

4. äºŒè¿›åˆ¶æ–‡ä»¶åˆ†æï¼š
   - æ–‡ä»¶ç±»å‹è¯†åˆ«
   - å“ˆå¸Œå€¼è®¡ç®—
   - æ–‡ä»¶å¤´åˆ†æ

5. æ—¥å¿—æ–‡ä»¶åˆ†æï¼š
   - å¤§æ–‡ä»¶çš„é€è¡Œå¤„ç†
   - æ­£åˆ™è¡¨è¾¾å¼å’Œå­—ç¬¦ä¸²è§£æ
   - æ•°æ®ç»Ÿè®¡å’Œå¯è§†åŒ–

6. æ–‡ä»¶å¤‡ä»½ç³»ç»Ÿï¼š
   - ç›®å½•éå†å’Œæ–‡ä»¶å¤åˆ¶
   - å…ƒæ•°æ®ç®¡ç†
   - ç‰ˆæœ¬æ§åˆ¶å’Œæ¢å¤

7. æ€§èƒ½ä¼˜åŒ–ï¼š
   - ä¸åŒI/Oæ–¹æ³•çš„æ€§èƒ½æ¯”è¾ƒ
   - ç¼“å†²åŒºå¤§å°çš„å½±å“
   - å†…å­˜ä½¿ç”¨ä¼˜åŒ–

å®é™…åº”ç”¨åœºæ™¯ï¼š
- æ•°æ®å¤„ç†å’Œåˆ†æ
- ç³»ç»Ÿç›‘æ§å’Œæ—¥å¿—åˆ†æ
- é…ç½®ç®¡ç†
- å¤‡ä»½å’Œæ¢å¤ç³»ç»Ÿ
- æ–‡ä»¶æ ¼å¼è½¬æ¢
- æ‰¹é‡æ–‡ä»¶æ“ä½œ

æœ€ä½³å®è·µæ€»ç»“ï¼š
1. å§‹ç»ˆä½¿ç”¨withè¯­å¥ç®¡ç†æ–‡ä»¶èµ„æº
2. é€‰æ‹©åˆé€‚çš„è¯»å†™æ–¹æ³•ä»¥ä¼˜åŒ–æ€§èƒ½
3. å¤„ç†å¤§æ–‡ä»¶æ—¶ä½¿ç”¨æµå¼å¤„ç†
4. å®ç°é€‚å½“çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
5. è€ƒè™‘è·¨å¹³å°å…¼å®¹æ€§
6. ä½¿ç”¨æ ‡å‡†åº“æ¨¡å—ï¼ˆcsvã€jsonç­‰ï¼‰å¤„ç†ç‰¹å®šæ ¼å¼
7. å®ç°æ•°æ®éªŒè¯å’Œå®Œæ•´æ€§æ£€æŸ¥
8. å®šæœŸå¤‡ä»½é‡è¦æ•°æ®

å…³é”®è¦ç‚¹ï¼š
- æ–‡ä»¶æ“ä½œæ˜¯ç³»ç»Ÿç¼–ç¨‹çš„åŸºç¡€
- æ€§èƒ½å’Œå¯é æ€§åŒæ ·é‡è¦
- é”™è¯¯å¤„ç†ä¸å¯å¿½è§†
- é€‰æ‹©åˆé€‚çš„å·¥å…·å’Œæ–¹æ³•
- è€ƒè™‘æ•°æ®çš„å®Œæ•´æ€§å’Œå®‰å…¨æ€§
""")


if __name__ == "__main__":
    main()